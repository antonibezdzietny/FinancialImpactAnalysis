{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read date database and mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts import DateFinanceReportDB\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "dateDB = DateFinanceReportDB()\n",
    "dateDB.loadDatabase(\"../database/reportsDate/dateDB\")\n",
    "date = dateDB.getDict()\n",
    "\n",
    "with open(\"../database/reportsDate/tickerMapper\", 'rb') as f:\n",
    "    ticker2dateName = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def castDate(date_list : list) -> np.datetime64:\n",
    "    return np.datetime64(f\"{date_list[-1]:04}-{date_list[-2]:02}-{date_list[-3]:02}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Annual Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports_path = \"../database/annualReports/\"\n",
    "end_subset = \"_Y_V.csv\" # _Y_D.csv || _Y_V.csv\n",
    "\n",
    "# Prepare list of ticker to parse\n",
    "wigs_list = pd.read_csv(\"../database/gpwCompaniesLists/WIGs.csv\")\n",
    "ticker_list = wigs_list.to_numpy().flatten()\n",
    "ticker_list = ticker_list[~pd.isnull(ticker_list)]\n",
    "\n",
    "merged_data = []\n",
    "for ticker in ticker_list:\n",
    "    # Read report\n",
    "    report = pd.read_csv(reports_path+ticker+end_subset).to_numpy().transpose()[1:]\n",
    "    report_years = report[:,0].astype(int)\n",
    "\n",
    "    publication_date = np.array(date[ticker2dateName[ticker]][\"Roczny\"])\n",
    "    publication_years = publication_date[:,2]\n",
    "\n",
    "    for i, report_year in enumerate(report_years):\n",
    "        for j, publication_year in enumerate(publication_years):\n",
    "            if report_year == publication_year:\n",
    "                row = report[i,:]\n",
    "                row[0] = castDate(publication_date[j])\n",
    "                row = np.insert(row, 0, ticker)\n",
    "                merged_data.append(row)\n",
    "                break\n",
    "\n",
    "merged_data_df = pd.DataFrame(merged_data)\n",
    "report = pd.read_csv(reports_path+ticker+end_subset)\n",
    "columns_names = report[\"Unnamed: 0\"].to_list()[1:]\n",
    "columns_names.insert(0, \"Ticker\")\n",
    "columns_names.insert(1, \"Data\")\n",
    "merged_data_df.columns = columns_names\n",
    "\n",
    "merged_data_df.to_csv(\"../database/mergedData/Annual_V.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports_path = \"../database/quarterlyReports/\"\n",
    "end_subset = \"_Q_D.csv\" # _Q_D.csv || _Q_V.csv\n",
    "\n",
    "# Prepare list of ticker to parse\n",
    "wigs_list = pd.read_csv(\"../database/gpwCompaniesLists/WIGs.csv\")\n",
    "ticker_list = wigs_list.to_numpy().flatten()\n",
    "ticker_list = ticker_list[~pd.isnull(ticker_list)]\n",
    "\n",
    "merged_data = []\n",
    "for ticker in ticker_list:\n",
    "    # Read report\n",
    "    report = pd.read_csv(reports_path+ticker+end_subset).to_numpy().transpose()[1:]\n",
    "    report_years = report[:,0]\n",
    "\n",
    "    quarter_list = [\"Q1\", \"Q2\", \"Q3\", \"Q4\"]\n",
    "    quarter_year = [[],[],[],[]]\n",
    "    for j in report_years:\n",
    "        for i, q in enumerate(quarter_list):\n",
    "            if j[-2:] == q:\n",
    "                quarter_year[i].append(int(j[:-3]))\n",
    "\n",
    "    for k, q in enumerate(quarter_list):\n",
    "        publication_date = np.array(date[ticker2dateName[ticker]][q])\n",
    "        if len(publication_date) == 0:\n",
    "            continue\n",
    "        publication_years = publication_date[:,2]\n",
    "\n",
    "        for i, report_year in enumerate(quarter_year[k]):\n",
    "            for j, publication_year in enumerate(publication_years):\n",
    "                if report_year == publication_year:\n",
    "                    row = report[i,:]\n",
    "                    row[0] = castDate(publication_date[j])\n",
    "                    row = np.insert(row, 0, ticker)\n",
    "                    merged_data.append(row)\n",
    "                    break\n",
    "\n",
    "merged_data_df = pd.DataFrame(merged_data)\n",
    "report = pd.read_csv(reports_path+ticker+end_subset)\n",
    "columns_names = report[\"Unnamed: 0\"].to_list()[1:]\n",
    "columns_names.insert(0, \"Ticker\")\n",
    "columns_names.insert(1, \"Data\")\n",
    "merged_data_df.columns = columns_names\n",
    "\n",
    "merged_data_df.to_csv(\"../database/mergedData/Quarterly_D.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
